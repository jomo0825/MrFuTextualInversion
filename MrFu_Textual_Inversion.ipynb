{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9eTVgigzgmT"
      },
      "outputs": [],
      "source": [
        "# Run this cell to DELETE log and output folder COMPLETELY!\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Delete the 'output' folder and its contents\n",
        "shutil.rmtree('output', ignore_errors=True)\n",
        "\n",
        "# Delete the 'log' folder and its contents\n",
        "shutil.rmtree('log', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "0wl0d-1HlRJZ",
        "outputId": "5a959071-d37d-4811-d007-6503eba705a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8ead808bc00b2fb21e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://8ead808bc00b2fb21e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/jomo0825/MrFuTextualInversion/main/textual_inversion.py\n",
        "!pip install gradio\n",
        "!pip install diffusers transformers accelerate ftfy\n",
        "\n",
        "import gradio as gr\n",
        "import sys\n",
        "import threading\n",
        "from textual_inversion import main as train_textual_inversion  # Assuming main function is the entry point in textual_inversion.py\n",
        "import time, os, logging\n",
        "from os import path\n",
        "import subprocess\n",
        "import shlex\n",
        "import queue\n",
        "from PIL import Image\n",
        "\n",
        "def parse_lr_schedule(lr_schedule_str):\n",
        "    schedule = []\n",
        "    segments = lr_schedule_str.split(',')\n",
        "    for segment in segments:\n",
        "        if ':' in segment:\n",
        "            lr, steps = segment.split(':')\n",
        "            schedule.append((float(lr), int(steps)))\n",
        "        else:\n",
        "            schedule.append((float(segment), None))  # Final constant learning rate\n",
        "    return schedule\n",
        "\n",
        "def get_learning_rate_at_step(lr_schedule, step):\n",
        "    current_step = 0\n",
        "    for lr, segment_steps in lr_schedule:\n",
        "        if segment_steps is None or step < current_step + segment_steps:\n",
        "            return lr\n",
        "        current_step += segment_steps\n",
        "    return lr_schedule[-1][0]  # Return the last LR if beyond defined steps\n",
        "\n",
        "# Callback to update the preview image in the UI\n",
        "def preview_callback(image, step):\n",
        "    global current_preview, current_status\n",
        "    current_preview = image\n",
        "    current_status = f\"Preview updated at step {step}\"\n",
        "\n",
        "def run_training(dataset_path, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                 learning_rate, batch_size, preview_save_steps, preview_seed):\n",
        "    global current_preview, current_status\n",
        "    current_preview = None  # Reset the preview\n",
        "    current_status = \"Training started...\"  # Initial status\n",
        "    output_dir = \"./output\"\n",
        "    logging_dir = \"./log\"\n",
        "\n",
        "    # Construct the command with all arguments\n",
        "    command = [\n",
        "        \"python\", \"textual_inversion.py\",\n",
        "        \"--pretrained_model_name_or_path\", \"stable-diffusion-v1-5/stable-diffusion-v1-5\",\n",
        "        \"--train_data_dir\", dataset_path,\n",
        "        \"--placeholder_token\", placeholder_token,\n",
        "        \"--initializer_token\", initializer_token,\n",
        "        \"--resolution\", \"512\",\n",
        "        \"--train_batch_size\", str(batch_size),\n",
        "        \"--gradient_accumulation_steps\", \"1\",\n",
        "        \"--learning_rate\", str(learning_rate),\n",
        "        \"--max_train_steps\", str(num_training_steps),\n",
        "        \"--save_steps\", str(preview_save_steps),\n",
        "        \"--validation_steps\", str(preview_save_steps),\n",
        "        \"--output_dir\", output_dir,\n",
        "        \"--logging_dir\", logging_dir,\n",
        "        \"--validation_prompt\", prompt,\n",
        "        \"--learnable_property\", \"object\",\n",
        "        \"--seed\", str(preview_seed)\n",
        "    ]\n",
        "\n",
        "    # Print the command for debugging\n",
        "    print(\"Command:\", \" \".join(command))\n",
        "\n",
        "    # Disable logging\n",
        "    logging.getLogger(\"accelerate\").disabled = True\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(logging_dir, exist_ok=True)\n",
        "    print(f\"Directories '{output_dir}' and '{logging_dir}' are ready.\")\n",
        "\n",
        "    # Run the command in a separate process\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Wait for the process to complete\n",
        "    stdout, stderr = process.communicate()\n",
        "\n",
        "    # Print the output and errors (for debugging)\n",
        "    print(\"Output:\", stdout.decode())\n",
        "    print(\"Errors:\", stderr.decode())\n",
        "\n",
        "    # Update status when training completes\n",
        "    current_status = \"Training completed!\"\n",
        "\n",
        "    # Update preview if available (this might need adjustments based on your preview logic)\n",
        "    if current_preview:\n",
        "        # Update the Gradio UI with the final preview\n",
        "        pass\n",
        "\n",
        "def ui():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Stable Diffusion Textual Inversion UI\")\n",
        "        gr.Markdown(\"Generate images using a preloaded textual inversion model.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            dataset_path = gr.Textbox(label=\"Dataset Path\", value=\"datasets\", interactive=True)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                placeholder_token = gr.Textbox(label=\"Placeholder Token\", placeholder=\"Enter placeholder token here\", interactive=True)\n",
        "                initializer_token = gr.Textbox(label=\"Initializer Token\", placeholder=\"Enter initializer token here\", interactive=True)\n",
        "                prompt = gr.Textbox(label=\"Preview Prompt\", placeholder=\"Enter your prompt here\", interactive=True)\n",
        "                num_training_steps = gr.Number(label=\"Number of Training Steps\", value=100, interactive=True)\n",
        "                learning_rate = gr.Number(label=\"Learning Rate\", value=0.001, interactive=True)\n",
        "                batch_size = gr.Number(label=\"Batch Size\", value=1, interactive=True)\n",
        "                preview_save_steps = gr.Number(label=\"Preview/Save Every N Steps\", value=10, interactive=True)\n",
        "                preview_seed = gr.Number(label=\"Preview Seed\", value=1, interactive=True)\n",
        "            with gr.Column(scale=1, min_width=300):\n",
        "                output_image = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "        generate_button = gr.Button(\"Start Training\")\n",
        "\n",
        "        generate_status = gr.Textbox(value=\"Status messages will appear here.\", label=\"Status\", interactive=False)\n",
        "\n",
        "        generate_button.click(\n",
        "            fn=run_training,\n",
        "            inputs=[dataset_path, prompt, placeholder_token, initializer_token, num_training_steps,\n",
        "                    learning_rate, batch_size, preview_save_steps, preview_seed],\n",
        "            outputs=[output_image, generate_status],\n",
        "            show_progress=True,\n",
        "            queue=True\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "demo = ui()\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp4gds97p4b1",
        "outputId": "6b88e4a4-09be-4fdc-9cf0-d2eb4edae506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7863\n"
          ]
        }
      ],
      "source": [
        "demo.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
